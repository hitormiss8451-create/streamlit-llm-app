from dotenv import load_dotenv

load_dotenv()
# app.py
# -*- coding: utf-8 -*-

import os
import streamlit as st

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã§ã¯ .envã€Cloud ã§ã¯ st.secrets ãŒä½¿ã‚ã‚Œã¾ã™ï¼‰---
try:
    # python-dotenv ãŒç„¡ã„ç’°å¢ƒã§ã‚‚è½ã¡ãªã„ã‚ˆã†ã« try/except
    from dotenv import load_dotenv
    load_dotenv()  # .env ãŒã‚ã‚Œã°èª­ã¿è¾¼ã‚€ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨ï¼‰
except Exception:
    pass

# --- LangChain ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆæ–°ã—ã„æ¨å¥¨ãƒ‘ã‚¹ï¼‰---
# æ—§: from langchain.chat_models import ChatOpenAI ã§ã¯ãªãã€
# æ–°: langchain_openai ã® ChatOpenAI ã‚’ä½¿ã„ã¾ã™
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# ========== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==========

def get_api_key() -> str | None:
    """Streamlit Secrets ã¾ãŸã¯ ç’°å¢ƒå¤‰æ•° ã‹ã‚‰ OPENAI_API_KEY ã‚’å–å¾—"""
    # Streamlit Cloud ã§ã¯ã€ŒApp settings â†’ Secretsã€ã§è¨­å®šã—ãŸå€¤ãŒ st.secrets ã‹ã‚‰å–ã‚Œã¾ã™
    key = st.secrets.get("OPENAI_API_KEY", None)
    if not key:
        key = os.getenv("OPENAI_API_KEY")
    return key

SYSTEM_PROMPTS = {
    "A": "ã‚ãªãŸã¯æ–™ç†ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¡ä»¶ã«å…·ä½“çš„ã§å†ç¾æ€§ã®é«˜ã„ãƒ¬ã‚·ãƒ”ã¨èª¿ç†ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ãã ã•ã„ã€‚",
    "B": "ã‚ãªãŸã¯çµŒæ¸ˆ/æŠ•è³‡ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦å…·ä½“çš„ã§å®Ÿå‹™çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ãã ã•ã„ã€‚"
}

def ask_expert(input_text: str, expert_choice: str, temperature: float = 0.2) -> str:
    if expert_choice not in SYSTEM_PROMPTS:
        raise ValueError("expert_choice ã¯ 'A' ã¾ãŸã¯ 'B' ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

    api_key = get_api_key()
    if not api_key:
        raise RuntimeError(
            "OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ã§ã¯ .env ã« "
            "OPENAI_API_KEY=... ã‚’è¨˜è¼‰ã€Streamlit Cloud ã§ã¯ Secrets ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )

    # LangChain OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆæœ€æ–°ã®æ¨å¥¨çµŒè·¯ï¼‰
    llm = ChatOpenAI(
        api_key=api_key,
        model="gpt-4o-mini",  # ã‚³ã‚¹ãƒˆã¨å¿œç­”å“è³ªã®ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ã€‚å¿…è¦ã«å¿œã˜ã¦å¤‰æ›´å¯ã€‚
        temperature=temperature,
    )

    messages = [
        SystemMessage(content=SYSTEM_PROMPTS[expert_choice]),
        HumanMessage(content=input_text),
    ]

    result = llm.invoke(messages)
    return result.content if hasattr(result, "content") else str(result)

# ========== Streamlit UI ==========

st.set_page_config(page_title="LLM Expert Helper", page_icon="ğŸ¤–", layout="centered")

st.title("LLM Expert Helper ğŸ¤–")
st.caption("Python 3.11 / LangChainï¼ˆlangchain_openaiï¼‰å¯¾å¿œç‰ˆãƒ»Streamlit Cloud äº’æ›")

with st.form("main_form"):
    expert_choice = st.selectbox("å°‚é–€å®¶ã‚’é¸æŠ", options=[("A", "æ–™ç†ã®å°‚é–€å®¶"), ("B", "çµŒæ¸ˆ/æŠ•è³‡ã®å°‚é–€å®¶")], index=0, format_func=lambda x: x[1])[0]
    user_input = st.text_area("è³ªå•å†…å®¹ã‚’å…¥åŠ›", placeholder="ä¾‹: é¶ã‚€ã­è‚‰ã§ä½œã‚Œã‚‹ç°¡å˜ã§é«˜ã‚¿ãƒ³ãƒ‘ã‚¯ãªãƒ¬ã‚·ãƒ”ã¯ï¼Ÿ", height=150)
    temperature = st.slider("å‡ºåŠ›ã®å¤šæ§˜æ€§ï¼ˆ0=å …å®Ÿ, 1=å¤šæ§˜ï¼‰", 0.0, 1.0, 0.2, 0.05)
    submitted = st.form_submit_button("å›ç­”ã™ã‚‹")

if submitted:
    try:
        if not user_input.strip():
            st.warning("è³ªå•å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("è€ƒãˆã¦ã„ã¾ã™..."):
                answer = ask_expert(user_input, expert_choice, temperature)
            st.success("å›ç­”")
            st.write(answer)
    except RuntimeError as e:
        # APIã‚­ãƒ¼æœªè¨­å®šãªã©ã®è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«åˆ†ã‹ã‚Šã‚„ã™ãè¡¨ç¤º
        st.error(str(e))
        st.info(
            "ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™º: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›´ä¸‹ã« `.env` ã‚’ä½œæˆã—ã¦ `OPENAI_API_KEY=...` ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚\n"
            "Streamlit Cloud: App settings â†’ Secrets ã« `OPENAI_API_KEY` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
    except Exception as e:
        # ãã‚Œä»¥å¤–ã¯è©³ç´°ã‚’è¦‹ã›ã¤ã¤è½ã¡ãªã„ã‚ˆã†ã«
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__}: {e}")
